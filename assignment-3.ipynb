{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a06e979-48a2-47ef-9e9d-25b70d7c6fc9",
   "metadata": {},
   "source": [
    "# Assignment 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a25a3-3e83-47b8-a8b4-8aa38c4663f9",
   "metadata": {},
   "source": [
    "Project Name: COSC102 - Assignment 3 â€“ Machine Learning Portfolio: Comparing the Performance of Machine Learning Approaches for Activity Classification <br>\n",
    "Authors: - <br>\n",
    "Email: - <br>\n",
    "Date: - 12/08/24<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ff6de-50e0-4a50-b81a-4b3a7ee7daff",
   "metadata": {},
   "source": [
    "BLOCK OF INFO EXPLAINING THE PROJECT AND WHAT WE WILL BE DOING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f66110b2-cc5d-476e-bd7c-d499a8eb3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9a76e-e7db-4045-a98c-6f91d9a0c904",
   "metadata": {},
   "source": [
    "We will begin by laoding up our data sets and running through the beginning checklist of any data science project. This includes<br>\n",
    "inspecting our data sets, checking for missing values and fixing any preliminary probelms we might see before moving onto the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9e2c7b0a-1cad-4558-bf15-28a4545f92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load csv files as pandas dataframe\n",
    "\n",
    "def load_data(csv, header, col_names):\n",
    "    \"\"\"\n",
    "    Takes a csv's file path in the form of a string and \n",
    "    returns a pandas dataframe of the csv, if the dataset\n",
    "    has no column names, it will append a passed in list\n",
    "    of column names, otherwise it will leave the dataset \n",
    "    as is.\n",
    "    Params:\n",
    "    String - csv, string of the file path for a given csv\n",
    "    header - paramater deciding if the first row of the csv \n",
    "    has column names or not\n",
    "    names - A list of column names to assign to the dataset\n",
    "    only if the headers parameter is \"None\"\n",
    "    Returns:\n",
    "    Pandas dataframe of our csv file\n",
    "    \"\"\"\n",
    "    return pd.read_csv(csv, header=header, names=col_names)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8537ecab-4e82-4faa-9f2b-eb986e5c4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for our csv data sets\n",
    "IMU_DATA = \"./a3_imu_data.csv\"\n",
    "ACTIVITY_DATA = \"./a3_activity_annotations.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661aafa-cb01-4d58-b701-6249abb737c9",
   "metadata": {},
   "source": [
    "Looking at the raw csv files outside of the project, we noticed that the imu data set has no column names, we are going to need<br>\n",
    "to assign the data set column names so that it is easier/possible to work with. The names chosen were taken from the assignments <br>\n",
    "task sheet. The activity data already had column names assigned and accurate, so no work was neccersary on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "03e84142-70c4-4d78-a744-c3062c1266cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialing our datasets as pandas dataframes and assigning column names\n",
    "\n",
    "# List of column namesColumn \n",
    "imu_col_names = [\"timestamp\", \"x_axis_accel\", \"y_axis_accel\", \"z_axis_accel\", \"x_axis_gyro\", \"y_axis_gyro\", \"z_axis_gyro\"]\n",
    "\n",
    "# Loading our csv files, the imu set has no column names so we are passing in a list of names to add\n",
    "# The activity dataset comes with names so we leave it as it is and pass in \"None\" for column names\n",
    "imu_data_raw = load_data(IMU_DATA, None, imu_col_names)\n",
    "activity_data_raw = load_data(ACTIVITY_DATA, \"infer\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "68556c60-7651-4e01-8660-c5a698b9f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for any null values\n",
    "\n",
    "def check_for_null(dataset, name):\n",
    "    \"\"\"\n",
    "    Takes a pandas dataframe and the name of the dataframe as a string and\n",
    "    checks if there are any missing values in all columns, prints out the \n",
    "    results\n",
    "    Params:\n",
    "    dataset - A pandas dataframe \n",
    "    name - A string for the name of your dataframe\n",
    "    \"\"\"\n",
    "    print(f\"{name}'s NULL values \\n\")\n",
    "    for col in dataset.columns:\n",
    "        print(f\"{dataset[col].name} has {dataset[col].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4015981f-734e-4aee-ad7e-1fe52beb27fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU DATA's NULL values \n",
      "\n",
      "timestamp has 0 null values\n",
      "x_axis_accel has 0 null values\n",
      "y_axis_accel has 0 null values\n",
      "z_axis_accel has 0 null values\n",
      "x_axis_gyro has 0 null values\n",
      "y_axis_gyro has 0 null values\n",
      "z_axis_gyro has 0 null values\n"
     ]
    }
   ],
   "source": [
    "check_for_null(imu_data_raw, \"IMU DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "42acb072-3ee7-47d1-8de0-d1bf6f0357b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVITY DATA's NAN values \n",
      "\n",
      "image has 0 null values\n",
      "xmin has 0 null values\n",
      "ymin has 0 null values\n",
      "xmax has 0 null values\n",
      "ymax has 0 null values\n",
      "label has 0 null values\n"
     ]
    }
   ],
   "source": [
    "check_for_null(activity_data_raw, \"ACTIVITY DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96803271-42b8-4bd5-89ab-6f2485abe9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22814634-7830-4475-a0b0-dc4b24069eb1",
   "metadata": {},
   "source": [
    "## Align and combine a dataset captured from an inertial sensor with an activity annotation file produced from a video recording of the data capture session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01251df6-962a-4da1-9d18-2bfdc628bdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c49239bb-b928-4722-af03-64cccf2c5ecb",
   "metadata": {},
   "source": [
    "## Visualize the combined dataset to check that the data has been correctly imported into Python and aligned with activity transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2da96-5ff0-4131-aee6-b90d10cdcccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f8bd36f-4865-4d4d-8fcf-dadd31d788dd",
   "metadata": {},
   "source": [
    "## Process the activity annotation data to assign a target activity to each data point within the IMU dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab104c0e-a239-4623-a325-eda01edde139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25adc5ba-dbee-491c-a1a6-da1dd3c233df",
   "metadata": {},
   "source": [
    "## Calculate a set of features from the raw sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa300e-71cb-4574-90a7-e033d394dde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc8bc013-23b9-4255-b040-4db9ada32af7",
   "metadata": {},
   "source": [
    "## Apply a machine learning workflow to test a selection of classification algorithms on the feature set for the task of activity classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ede18-4454-45a7-9e03-e292870b03f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b381fb6a-210c-4a84-acb9-c6bd776f513c",
   "metadata": {},
   "source": [
    "## Perform hyper-parameter optimization on at least one parameter for each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c080cc-eb4a-4c11-a658-0eb83659da10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "014f4a54-9655-4f05-8830-007260b3cf7b",
   "metadata": {},
   "source": [
    "## Create some visualizations and report on the model that your machine learning approaches have learned from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd6ddb-5035-4bb6-999d-2037f7acd295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
